{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Lyrics Database\n",
    "This file articulates the way the database of lyrics was compiled. All lyrics were scraped from [AZLyrics.com](www.azlyrics.com), while the artists and specific songs selected came from [IMDB](https://www.imdb.com/list/ls058480497/) and [Wikipedia](https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_1960).\n",
    "\n",
    "## Import Libraries & Define Critical Functions\n",
    "The three primary functions used in this file were:\n",
    "- **get_soup:** Default function for getting html data from a website and preparing it for parsing.\n",
    "- **get_artist_songs:** Given an artist name, this function attempts to retrieve the list of songs with the corresponding URL's for lyrics.\n",
    "- **get_lyrics:** Uses links for songs to get lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    html_page = requests.get(url) #Make a get request to retrieve the page\n",
    "    soup = BeautifulSoup(html_page.content, 'html.parser') #Pass the page contents to beautiful soup for parsing\n",
    "    return soup\n",
    "\n",
    "\n",
    "def get_artist_songs(artist):\n",
    "    # Remove non-alphanumeric characters from artist name\n",
    "    clean_name = re.sub(r'\\W+', '', artist.lower())\n",
    "    \n",
    "    # Create directory for saving song data\n",
    "    new_dir = f'lyrics/{artist}'\n",
    "    try:\n",
    "        os.makedirs(new_dir)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Scrape artist page for song names and links\n",
    "    url = f'https://www.azlyrics.com/{clean_name[0]}/{clean_name}.html'\n",
    "    soup = get_soup(url)\n",
    "    \n",
    "    song_tags = soup.find_all('div', class_='listalbum-item')\n",
    "    \n",
    "    songs = []\n",
    "    song_links = []\n",
    "    for song in song_tags:\n",
    "        for a in song.find_all('a', href=True):\n",
    "            song_link = f\"https://www.azlyrics.com{a['href'][2:]}\"\n",
    "            if '+' not in song_link:\n",
    "                songs.append(song.text)\n",
    "                song_links.append(song_link)\n",
    "            \n",
    "    return songs, song_links\n",
    "\n",
    "\n",
    "def get_lyrics(song, link):\n",
    "    soup = get_soup(link)\n",
    "    lyrics = soup.find_all('div', class_=None)[1].text.strip()\n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get List of Top 100 Artists from IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape IMDB\n",
    "url = 'https://www.imdb.com/list/ls058480497/'\n",
    "soup = get_soup(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hank Williams',\n",
       " 'Frank Sinatra',\n",
       " 'Bo Diddley',\n",
       " 'Ray Charles',\n",
       " 'Little Richard']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract list of artist names to list\n",
    "artists = []\n",
    "for item in soup.find_all(\"h3\", class_=\"lister-item-header\"):\n",
    "    txt = item.text.split('. ')[1].strip().replace('.', '')\n",
    "    if txt[:4] == 'The ':\n",
    "        txt = txt[4:]\n",
    "    artists.append(txt)\n",
    "    \n",
    "artists[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Artist Names for AZLyrics Search\n",
    "The code below cycles through each artist and each song, saving each set of song lyrics to its own text file. The lyrics folder contains folders for each artist, which contains a random selection of song lyrics for each artist (approx 15% of all artist songs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "for artist in artists:\n",
    "    # Get song names and links for given artist\n",
    "    songs, song_links = get_artist_songs(artist)\n",
    "    \n",
    "    # Pause for a few seconds to not overwhelm azlyrics server\n",
    "    time.sleep(np.random.randint(2, 8) + np.random.random())\n",
    "    \n",
    "    for song, link in zip(songs, song_links):\n",
    "        # Select random number to determine whether or not to get songs for given song\n",
    "        n = np.random.random()\n",
    "        if n >.85 and len(os.listdir(f'lyrics/{artist}')) < 20:\n",
    "            \n",
    "            # Write lyrics to file if not error\n",
    "            try:\n",
    "                lyrics = get_lyrics(song, link)\n",
    "                with open(f\"lyrics/{artist}/{song.lower().replace(' ', '_')}.txt\", 'w') as f:\n",
    "                    f.write(lyrics)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Pause before checking next song/artist\n",
    "            time.sleep(np.random.randint(2, 8) + np.random.random())\n",
    "            \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up\n",
    "In some cases, the artist name from IMDB does not match with AZLyrics formatting, so no data is gathered, or very limited data is gathered. The code below removes directory folders where artist data was too limited for practical use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in artists:\n",
    "    try:\n",
    "        if len(os.listdir(f'lyrics/{artist}')) < 2:\n",
    "            os.rmdir(f'lyrics/{artist}')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Top 10 Billboard Songs for Each Year Since 1960\n",
    "The data in Wikipedia is not formatted the same way for each year, so code will have to be modified for different time periods.\n",
    "\n",
    "### 1960 - 1981"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary for storing song and artist data\n",
    "billboard_dict = {\n",
    "    'Rank': [],\n",
    "    'Year': [],\n",
    "    'Song': [],\n",
    "    'Artist': []\n",
    "}\n",
    "\n",
    "# Get top 10 songs with artists for each year from wikipedia\n",
    "for yr in range(1960, 1982):\n",
    "    url = f'https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_{yr}'\n",
    "    soup = get_soup(url)\n",
    "    \n",
    "    # Song & artist are 2nd and 3rd columns in each row of table data\n",
    "    raw = soup.find_all('td')[:30]\n",
    "    data = [raw[i].text for i in range(len(raw)) if i%3!=0]\n",
    "\n",
    "    # Iteratively append data to dictionary\n",
    "    i=0\n",
    "    for n in range(10):\n",
    "        billboard_dict['Rank'].append(i+1)\n",
    "        billboard_dict['Year'].append(yr)\n",
    "        billboard_dict['Song'].append(data[n+i].replace('\"', '').strip())\n",
    "        billboard_dict['Artist'].append(data[n+i+1].replace('\"', '').strip())\n",
    "        i+=1\n",
    "        \n",
    "    # Pause before scraping next page\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1982-2019 (excl. 2012-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record Count: 400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1960</td>\n",
       "      <td>Theme from A Summer Place</td>\n",
       "      <td>Percy Faith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1961</td>\n",
       "      <td>Tossin' and Turnin'</td>\n",
       "      <td>Bobby Lewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1962</td>\n",
       "      <td>Stranger on the Shore</td>\n",
       "      <td>Acker Bilk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1963</td>\n",
       "      <td>Surfin' U.S.A.</td>\n",
       "      <td>The Beach Boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>1964</td>\n",
       "      <td>I Want to Hold Your Hand</td>\n",
       "      <td>The Beatles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank  Year                       Song          Artist\n",
       "0      1  1960  Theme from A Summer Place     Percy Faith\n",
       "10     1  1961        Tossin' and Turnin'     Bobby Lewis\n",
       "20     1  1962      Stranger on the Shore      Acker Bilk\n",
       "30     1  1963             Surfin' U.S.A.  The Beach Boys\n",
       "40     1  1964   I Want to Hold Your Hand     The Beatles"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get top 10 songs with artists for each year from wikipedia\n",
    "for yr in [i for i in range(1982, 2020) if i not in [2012, 2013]]:\n",
    "    url = f'https://en.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_{yr}'\n",
    "    soup = get_soup(url)\n",
    "    \n",
    "    # Song & artist are 2nd and 3rd columns in each row of table data\n",
    "    raw = soup.find_all('td')[:30]\n",
    "    data = [raw[i].find_next('a').text for i in range(len(raw))]\n",
    "\n",
    "    # Iteratively append data to dictionary\n",
    "    for n in range(10):\n",
    "        if n%2==0:\n",
    "            billboard_dict['Rank'].append(n+1)\n",
    "            billboard_dict['Year'].append(yr)\n",
    "            billboard_dict['Song'].append(data[n].replace('\"', '').strip())\n",
    "        else:\n",
    "            billboard_dict['Artist'].append(data[n].replace('\"', '').strip())\n",
    "        i+=1\n",
    "        \n",
    "    # Pause before scraping next page\n",
    "    time.sleep(5)\n",
    "\n",
    "# Convert to dataframe and save as CSV\n",
    "billboard_df = pd.DataFrame.from_dict(billboard_dict).sort_values(['Rank', 'Year'])\n",
    "print(f'Record Count: {len(billboard_df)}')\n",
    "billboard_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "errors=0\n",
    "for i in range(len(billboard_df)):\n",
    "    t0 = time.time()\n",
    "    Artist = billboard_df.Artist[i]\n",
    "    Artist = Artist if Artist[:4] != 'The ' else Artist[4:]\n",
    "    artist = re.sub(r'\\W+', '', Artist.lower())\n",
    "    \n",
    "    Song = billboard_df.Song[i]\n",
    "    song = re.sub(r'\\W+', '', Song.lower())\n",
    "    \n",
    "    url = f\"https://www.azlyrics.com/lyrics/{artist}/{song}.html\"\n",
    "    try:\n",
    "        lyrics = get_lyrics(Song, url)\n",
    "        if len(lyrics)>50:\n",
    "            new_dir = f'lyrics/{Artist}'\n",
    "            time.sleep(np.random.randint(2, 5) + np.random.random())\n",
    "            try:\n",
    "                os.makedirs(new_dir)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            with open(f\"lyrics/{Artist}/{Song.lower().replace(' ', '_')}.txt\", 'w') as f:\n",
    "                        f.write(lyrics)\n",
    "        \n",
    "    except:\n",
    "        errors+=1\n",
    "        print('-----------Error-----------')\n",
    "        if errors == 10:\n",
    "            break\n",
    "    \n",
    "    j+=1\n",
    "    t1 = time.time()\n",
    "    print(f'{j}. {Artist}: {Song} ({t1-t0:.1f}): {url}')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create JSON for Database Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dict = {}\n",
    "\n",
    "for artist in os.listdir('lyrics/'):\n",
    "    if artist != '.DS_Store':\n",
    "        db_dict[artist]={'song_names': [], 'file_names': []}\n",
    "        for file in os.listdir(f'lyrics/{artist}'):\n",
    "            song_name = file.replace('.txt', '').replace('_', ' ').title()\n",
    "            db_dict[artist]['file_names'].append(file)\n",
    "            db_dict[artist]['song_names'].append(song_name)\n",
    "            \n",
    "with open(\"lyrics.json\", \"w\") as outfile:  \n",
    "    json.dump(db_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
